apiVersion: v1
kind: Namespace
metadata:
  name: gpu-workloads
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: gpu-monitoring-config
  namespace: gpu-workloads
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
    scrape_configs:
      - job_name: 'nvidia-gpu'
        static_configs:
          - targets: ['localhost:9400']
      - job_name: 'amd-gpu'
        static_configs:
          - targets: ['localhost:9401']
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: gpu-monitoring
  namespace: gpu-workloads
spec:
  replicas: 1
  selector:
    matchLabels:
      app: gpu-monitoring
  template:
    metadata:
      labels:
        app: gpu-monitoring
    spec:
      nodeSelector:
        "kubernetes.azure.com/gpu-accelerator": "nvidia-tesla-t4"  # For NVIDIA T4 GPUs
      containers:
      - name: nvidia-monitor
        image: nvidia/cuda:11.8.0-base-ubuntu22.04
        command: ["/bin/bash", "-c"]
        args:
        - |
          apt-get update && apt-get install -y nvidia-smi
          while true; do
            nvidia-smi --query-gpu=utilization.gpu,memory.used,memory.total,temperature.gpu,power.draw --format=csv,noheader,nounits
            sleep 15
          done
        resources:
          limits:
            nvidia.com/gpu: 1
        volumeMounts:
        - name: nvidia-driver
          mountPath: /usr/local/nvidia
      - name: amd-monitor
        image: rocm/rocm-terminal:latest
        command: ["/bin/bash", "-c"]
        args:
        - |
          while true; do
            rocm-smi --showuse --showmeminfo --showtemp --showpower
            sleep 15
          done
        resources:
          limits:
            amd.com/gpu: 1
      volumes:
      - name: nvidia-driver
        hostPath:
          path: /usr/local/nvidia
---
apiVersion: v1
kind: Service
metadata:
  name: gpu-monitoring
  namespace: gpu-workloads
spec:
  selector:
    app: gpu-monitoring
  ports:
  - name: nvidia-metrics
    port: 9400
    targetPort: 9400
  - name: amd-metrics
    port: 9401
    targetPort: 9401
  type: ClusterIP
---
# Azure GPU Node Pool Configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: nvidia-device-plugin-config
  namespace: kube-system
data:
  config.json: |
    {
      "version": "v1",
      "sharing": {
        "mpsPerDevice": 1
      }
    } 